# Awesome Data Poisoning[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
A curated list of papers & resources linked to data poisoning.

## Papers

### Attacks
+ BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain (arxiv 2017) [[paper](https://arxiv.org/pdf/1708.06733)]
+ Targeted backdoor attacks on deep learning systems using data poisoning (arvis 2017) [[paper](https://arxiv.org/abs/1712.05526)]
+ Trojaning attack on neural networks (NDSS 2018) [[paper](https://arxiv.org/abs/1712.05526)]
+ Label-consistent backdoor attacks (arxiv 2019) [[paper](https://arxiv.org/abs/1912.02771)]
+ Invisible backdoor attacks on deep neural networks via steganography and regularization (TDSC 2020) [[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186317&casa_token=oIzySL0ff20AAAAA:J_sBK-x736EqoE8mGUNcDvT79YINxvpTRL6Gx_V98dH46quPMFThYeWCNmcPyupRfK5U4mZJ&tag=1)]
+ Backdooring and poisoning neural networks with image-scaling attacks (arxiv 2020) [[paper](https://arxiv.org/abs/2003.08633)]
+ MetaPoison: Practical General-purpose Clean-label Data Poisoning (NeurIPS 2020) [[paper](https://arxiv.org/abs/2004.00225v2)]
+ How To Backdoor Federated Learning (AISTATS 2020) [[paper](http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf)]

### Defenses
+ Certified Defenses for Data Poisoning Attacks (NeurIPS 2017) [[paper](https://arxiv.org/abs/1706.03691v2)]
+ Spectral Signatures in Backdoor Attacks (NeurIPS 2018) [[paper](https://proceedings.neurips.cc/paper/2018/file/280cf18baf4311c92aa5a042336587d3-Paper.pdf)]
+ Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise (NeurIPS 2018) [[paper](https://arxiv.org/abs/1802.05300)]
+ Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks (NeurIPS 2018) [[paper](https://arxiv.org/abs/1804.00792v2)]
+ Sever: A Robust Meta-Algorithm for Stochastic Optimization (ICML 2019) [[paper](http://proceedings.mlr.press/v97/diakonikolas19a/diakonikolas19a.pdf)]
+ Learning with Bad Training Data via Iterative Trimmed Loss Minimization (ICML 2019) [[paper](http://proceedings.mlr.press/v97/shen19e/shen19e.pdf)]
+ Data Poisoning Attacks in Multi-Party Learning (ICML 2019) [[paper](http://proceedings.mlr.press/v97/mahloujifar19a/mahloujifar19a.pdf)]
+ Transferable Clean-Label Poisoning Attacks on Deep Neural Nets (ICML 2019) [[paper](https://arxiv.org/abs/1905.05897)]
+ The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure (AAAI 2019) [[paper](https://arxiv.org/abs/1809.03063)]
+ Reflection backdoor: A natural backdoor attack on deep neural networks (ECCV 2020) [[paper](https://arxiv.org/abs/2007.02343)]
+ Radioactive data: tracing through training (ICML 2020) [[paper](https://arxiv.org/abs/2002.00937)]
+ SPECTRE: Defending Against Backdoor Attacks Using Robust Covariance Estimation (ICML 2021) [[paper](https://homes.cs.washington.edu/~sewoong/backdoor.pdf)]

### Benchmark
+ Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks (ICML 2021) [[paper](https://arxiv.org/pdf/2006.12557)] [[code](https://github.com/aks2203/poisoning-benchmark)]