# Awesome Data Poisoning
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of papers & resources linked to data poisoning.

## Papers

### Attacks
+ BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain (arXiv 2017) [[paper](https://arxiv.org/abs/1708.06733)]
+ Targeted backdoor attacks on deep learning systems using data poisoning (arXiv 2017) [[paper](https://arxiv.org/abs/1712.05526)]
+ Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning (arXiv 2017) [[paper](https://arxiv.org/abs/1712.05526)]
+ Label-consistent backdoor attacks (arXiv 2019) [[paper](https://arxiv.org/abs/1912.02771)]
+ Invisible backdoor attacks on deep neural networks via steganography and regularization (TDSC 2020) [[paper](https://ieeexplore.ieee.org/abstract/document/9186317)]
+ Backdooring and poisoning neural networks with image-scaling attacks (arXiv 2020) [[paper](https://arxiv.org/abs/2003.08633)]
+ MetaPoison: Practical General-purpose Clean-label Data Poisoning (NeurIPS 2020) [[paper](https://arxiv.org/abs/2004.00225)]
+ How To Backdoor Federated Learning (AISTATS 2020) [[paper](https://proceedings.mlr.press/v108/bagdasaryan20a.html)]

### Defenses
+ Certified Defenses for Data Poisoning Attacks (NeurIPS 2017) [[paper](https://arxiv.org/abs/1706.03691)]
+ Spectral Signatures in Backdoor Attacks (NeurIPS 2018) [[paper](https://proceedings.neurips.cc/paper/2018/hash/280cf18baf4311c92aa5a042336587d3-Abstract.html)]
+ Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise (NeurIPS 2018) [[paper](https://arxiv.org/abs/1802.05300)]
+ Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks (NeurIPS 2018) [[paper](https://arxiv.org/abs/1804.00792)]
+ Sever: A Robust Meta-Algorithm for Stochastic Optimization (ICML 2019) [[paper](https://proceedings.mlr.press/v97/diakonikolas19a.html)]
+ Learning with Bad Training Data via Iterative Trimmed Loss Minimization (ICML 2019) [[paper](https://proceedings.mlr.press/v97/shen19e.html)]
+ Universal Multi-Party Poisoning Attacks
 (ICML 2019) [[paper](https://proceedings.mlr.press/v97/mahloujifar19a.html)]
+ Transferable Clean-Label Poisoning Attacks on Deep Neural Nets (ICML 2019) [[paper](https://arxiv.org/abs/1905.05897)]
+ The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure (AAAI 2019) [[paper](https://arxiv.org/abs/1809.03063)]
+ Reflection backdoor: A natural backdoor attack on deep neural networks (ECCV 2020) [[paper](https://arxiv.org/abs/2007.02343)]
+ Radioactive data: tracing through training (ICML 2020) [[paper](https://arxiv.org/abs/2002.00937)]
+ SPECTRE: Defending Against Backdoor Attacks Using Robust Covariance Estimation (ICML 2021) [[paper](https://proceedings.mlr.press/v139/hayase21a.html)]

### Benchmark
+ Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks (ICML 2021) [[paper](https://arxiv.org/pdf/2006.12557)] [[code](https://github.com/aks2203/poisoning-benchmark)]